[2025-08-28 01:22:39] step: 0, train loss: 1.118, val loss: 1.126
[2025-08-28 01:26:37] step: 500, train loss: 1.127, val loss: 1.121

[2025-08-28 01:29:19] step: 0, train loss: 1.116, val loss: 1.118
[2025-08-28 01:33:18] step: 500, train loss: 1.115, val loss: 1.131
[2025-08-28 01:37:39] step: 1000, train loss: 1.117, val loss: 1.122
[2025-08-28 01:41:23] step: 1500, train loss: 1.121, val loss: 1.121
[2025-08-28 01:45:07] step: 2000, train loss: 1.103, val loss: 1.119
[2025-08-28 01:48:51] step: 2500, train loss: 1.125, val loss: 1.132
[2025-08-28 01:52:39] step: 3000, train loss: 1.116, val loss: 1.123
[2025-08-28 01:57:33] step: 3500, train loss: 1.110, val loss: 1.118
[2025-08-28 02:01:31] step: 4000, train loss: 1.114, val loss: 1.109
[2025-08-28 02:05:27] step: 4500, train loss: 1.113, val loss: 1.106
[2025-08-28 02:09:28] step: 5000, train loss: 1.101, val loss: 1.108
[2025-08-28 02:13:42] step: 5500, train loss: 1.107, val loss: 1.103
[2025-08-28 02:17:59] step: 6000, train loss: 1.101, val loss: 1.101
[2025-08-28 02:22:58] step: 6500, train loss: 1.106, val loss: 1.123
[2025-08-28 02:27:02] step: 7000, train loss: 1.110, val loss: 1.120
[2025-08-28 02:31:00] step: 7500, train loss: 1.094, val loss: 1.131
[2025-08-28 02:34:59] step: 8000, train loss: 1.106, val loss: 1.116
[2025-08-28 02:38:56] step: 8500, train loss: 1.109, val loss: 1.110
[2025-08-28 02:42:53] step: 9000, train loss: 1.128, val loss: 1.119
[2025-08-28 02:46:50] step: 9500, train loss: 1.107, val loss: 1.114
[2025-08-28 02:50:48] step: 10000, train loss: 1.099, val loss: 1.108
[2025-08-28 02:54:49] step: 10500, train loss: 1.105, val loss: 1.101
[2025-08-28 02:58:49] step: 11000, train loss: 1.115, val loss: 1.111
[2025-08-28 03:02:46] step: 11500, train loss: 1.101, val loss: 1.100
[2025-08-28 03:06:43] step: 12000, train loss: 1.114, val loss: 1.106
[2025-08-28 03:10:40] step: 12500, train loss: 1.101, val loss: 1.116
[2025-08-28 03:14:37] step: 13000, train loss: 1.105, val loss: 1.104
[2025-08-28 03:18:30] step: 13500, train loss: 1.106, val loss: 1.120
[2025-08-28 03:22:22] step: 14000, train loss: 1.109, val loss: 1.112
[2025-08-28 03:26:15] step: 14500, train loss: 1.114, val loss: 1.126

[2025-08-28 04:02:43] step: 0, train loss: 1.105, val loss: 1.111

[2025-08-28 04:24:36] step: 0, train loss: 1.109, val loss: 1.086

[2025-08-28 04:58:11] step: 0, train loss: 1.133, val loss: 1.117
[2025-08-28 05:06:14] step: 1000, train loss: 1.117, val loss: 1.116
[2025-08-28 05:13:55] step: 2000, train loss: 1.112, val loss: 1.107
[2025-08-28 05:21:23] step: 3000, train loss: 1.098, val loss: 1.114
[2025-08-28 05:28:51] step: 4000, train loss: 1.114, val loss: 1.121
[2025-08-28 05:36:20] step: 5000, train loss: 1.109, val loss: 1.109
[2025-08-28 05:43:49] step: 6000, train loss: 1.106, val loss: 1.120
[2025-08-28 05:51:18] step: 7000, train loss: 1.097, val loss: 1.097
[2025-08-28 05:58:46] step: 8000, train loss: 1.097, val loss: 1.109
[2025-08-28 06:06:13] step: 9000, train loss: 1.116, val loss: 1.124
[2025-08-28 06:13:39] step: 10000, train loss: 1.105, val loss: 1.101
[2025-08-28 06:21:05] step: 11000, train loss: 1.106, val loss: 1.098
[2025-08-28 06:28:31] step: 12000, train loss: 1.095, val loss: 1.108
[2025-08-28 06:35:57] step: 13000, train loss: 1.105, val loss: 1.114
[2025-08-28 06:43:23] step: 14000, train loss: 1.102, val loss: 1.091
[2025-08-28 06:50:49] step: 15000, train loss: 1.112, val loss: 1.107
[2025-08-28 06:58:15] step: 16000, train loss: 1.091, val loss: 1.096
[2025-08-28 07:05:41] step: 17000, train loss: 1.100, val loss: 1.106
[2025-08-28 07:13:08] step: 18000, train loss: 1.102, val loss: 1.111
[2025-08-28 07:20:35] step: 19000, train loss: 1.101, val loss: 1.095
[2025-08-28 07:28:01] step: 20000, train loss: 1.104, val loss: 1.095
[2025-08-28 07:35:27] step: 21000, train loss: 1.092, val loss: 1.097
[2025-08-28 07:42:53] step: 22000, train loss: 1.095, val loss: 1.105
[2025-08-28 07:50:19] step: 23000, train loss: 1.100, val loss: 1.093
[2025-08-28 07:57:45] step: 24000, train loss: 1.084, val loss: 1.103
[2025-08-28 08:05:11] step: 25000, train loss: 1.114, val loss: 1.097
[2025-08-28 08:12:38] step: 26000, train loss: 1.092, val loss: 1.098
[2025-08-28 08:20:04] step: 27000, train loss: 1.093, val loss: 1.096
[2025-08-28 08:27:30] step: 28000, train loss: 1.089, val loss: 1.088
[2025-08-28 08:34:56] step: 29000, train loss: 1.088, val loss: 1.097
[2025-08-28 08:42:22] step: 30000, train loss: 1.095, val loss: 1.092
[2025-08-28 08:49:49] step: 31000, train loss: 1.095, val loss: 1.098
[2025-08-28 08:57:15] step: 32000, train loss: 1.091, val loss: 1.101

[2025-08-28 16:21:25] step: 0, train loss: 1.085, val loss: 1.108
[2025-08-28 16:25:09] step: 500, train loss: 1.100, val loss: 1.094
[2025-08-28 16:29:01] step: 1000, train loss: 1.085, val loss: 1.083
[2025-08-28 16:33:02] step: 1500, train loss: 1.082, val loss: 1.073
[2025-08-28 16:37:03] step: 2000, train loss: 1.101, val loss: 1.097
[2025-08-28 16:41:04] step: 2500, train loss: 1.098, val loss: 1.091

[2025-08-28 16:48:43] step: 0, train loss: 1.085, val loss: 1.088
[2025-08-28 16:49:30] step: 100, train loss: 1.105, val loss: 1.083

[2025-08-28 16:50:26] step: 0, train loss: 1.097, val loss: 1.131
[2025-08-28 16:51:12] step: 100, train loss: 1.087, val loss: 1.087
[2025-08-28 16:51:59] step: 200, train loss: 1.117, val loss: 1.085

[2025-08-28 16:55:39] step: 0, train loss: 1.092, val loss: 1.097
[2025-08-28 16:59:36] step: 500, train loss: 1.093, val loss: 1.083
[2025-08-28 17:03:37] step: 1000, train loss: 1.087, val loss: 1.085
[2025-08-28 17:07:39] step: 1500, train loss: 1.102, val loss: 1.102

[2025-08-28 17:46:19] step: 0, train loss: 1.092, val loss: 1.093

[2025-08-28 18:30:11] step: 0, train loss: 1.086, val loss: 1.082
[2025-08-28 18:38:09] step: 1000, train loss: 1.088, val loss: 1.084
[2025-08-28 18:46:07] step: 2000, train loss: 1.079, val loss: 1.089
[2025-08-28 18:54:02] step: 3000, train loss: 1.096, val loss: 1.093
[2025-08-28 19:01:35] step: 4000, train loss: 1.085, val loss: 1.089
[2025-08-28 19:09:08] step: 5000, train loss: 1.088, val loss: 1.094
[2025-08-28 19:16:40] step: 6000, train loss: 1.085, val loss: 1.082
[2025-08-28 19:24:16] step: 7000, train loss: 1.089, val loss: 1.087
[2025-08-28 19:31:53] step: 8000, train loss: 1.093, val loss: 1.090
[2025-08-28 19:39:40] step: 9000, train loss: 1.087, val loss: 1.090

[2025-08-28 20:33:18] step: 0, train loss: 1.078, val loss: 1.079
[2025-08-28 20:41:20] step: 1000, train loss: 1.085, val loss: 1.090
[2025-08-28 20:49:24] step: 2000, train loss: 1.078, val loss: 1.097
[2025-08-28 20:57:11] step: 3000, train loss: 1.078, val loss: 1.088
[2025-08-28 21:04:48] step: 4000, train loss: 1.084, val loss: 1.080
[2025-08-28 21:12:33] step: 5000, train loss: 1.080, val loss: 1.096
[2025-08-28 21:20:27] step: 6000, train loss: 1.074, val loss: 1.078
[2025-08-28 21:28:23] step: 7000, train loss: 1.082, val loss: 1.091
[2025-08-28 21:36:17] step: 8000, train loss: 1.091, val loss: 1.083
[2025-08-28 21:44:13] step: 9000, train loss: 1.079, val loss: 1.075

[2025-08-29 06:49:50] step: 0, train loss: 2.278, val loss: 2.274
[2025-08-29 06:52:13] step: 500, train loss: 1.585, val loss: 1.598
[2025-08-29 06:54:25] step: 1000, train loss: 1.059, val loss: 1.060
[2025-08-29 06:56:38] step: 1500, train loss: 1.050, val loss: 1.033
[2025-08-29 06:59:00] step: 2000, train loss: 1.035, val loss: 1.020
[2025-08-29 07:01:23] step: 2500, train loss: 1.031, val loss: 1.031
[2025-08-29 07:03:48] step: 3000, train loss: 1.012, val loss: 1.013
[2025-08-29 07:06:14] step: 3500, train loss: 1.016, val loss: 1.010
[2025-08-29 07:08:37] step: 4000, train loss: 1.031, val loss: 1.014
[2025-08-29 07:11:02] step: 4500, train loss: 1.010, val loss: 1.006

[2025-08-29 07:15:02] step: 0, train loss: 0.998, val loss: 1.012
[2025-08-29 07:17:36] step: 500, train loss: 1.002, val loss: 1.008
[2025-08-29 07:20:02] step: 1000, train loss: 1.007, val loss: 0.999
[2025-08-29 07:22:31] step: 1500, train loss: 1.001, val loss: 0.995
[2025-08-29 07:24:44] step: 2000, train loss: 1.002, val loss: 1.006
[2025-08-29 07:26:55] step: 2500, train loss: 1.000, val loss: 1.001
[2025-08-29 07:29:05] step: 3000, train loss: 1.003, val loss: 0.987
[2025-08-29 07:31:16] step: 3500, train loss: 1.001, val loss: 0.990
[2025-08-29 07:33:27] step: 4000, train loss: 0.992, val loss: 0.991
[2025-08-29 07:35:38] step: 4500, train loss: 0.991, val loss: 0.980

[2025-08-29 07:38:19] step: 0, train loss: 0.985, val loss: 0.992
[2025-08-29 07:40:42] step: 500, train loss: 0.976, val loss: 0.980
[2025-08-29 07:43:04] step: 1000, train loss: 0.983, val loss: 0.992
[2025-08-29 07:45:28] step: 1500, train loss: 0.988, val loss: 0.996
[2025-08-29 07:47:52] step: 2000, train loss: 0.977, val loss: 0.975
[2025-08-29 07:50:17] step: 2500, train loss: 0.993, val loss: 0.982
[2025-08-29 07:52:38] step: 3000, train loss: 0.976, val loss: 0.980
[2025-08-29 07:54:52] step: 3500, train loss: 0.981, val loss: 0.974
[2025-08-29 07:57:13] step: 4000, train loss: 0.986, val loss: 0.969
[2025-08-29 07:59:37] step: 4500, train loss: 0.985, val loss: 0.984

[2025-08-29 08:02:55] step: 0, train loss: 0.983, val loss: 0.969
[2025-08-29 08:05:19] step: 500, train loss: 0.971, val loss: 0.966
[2025-08-29 08:07:43] step: 1000, train loss: 0.977, val loss: 0.967
[2025-08-29 08:10:08] step: 1500, train loss: 0.978, val loss: 0.966
[2025-08-29 08:12:29] step: 2000, train loss: 0.962, val loss: 0.969
[2025-08-29 08:14:44] step: 2500, train loss: 0.965, val loss: 0.967
[2025-08-29 08:17:00] step: 3000, train loss: 0.970, val loss: 0.970
[2025-08-29 08:19:16] step: 3500, train loss: 0.967, val loss: 0.954
[2025-08-29 08:21:34] step: 4000, train loss: 0.966, val loss: 0.977
[2025-08-29 08:23:51] step: 4500, train loss: 0.967, val loss: 0.974

[2025-08-29 08:26:31] step: 0, train loss: 0.970, val loss: 0.966
[2025-08-29 08:28:50] step: 500, train loss: 0.979, val loss: 0.962
[2025-08-29 08:31:11] step: 1000, train loss: 0.968, val loss: 0.971
[2025-08-29 08:33:32] step: 1500, train loss: 0.969, val loss: 0.977
[2025-08-29 08:35:55] step: 2000, train loss: 0.970, val loss: 0.972
[2025-08-29 08:38:20] step: 2500, train loss: 0.967, val loss: 0.963
[2025-08-29 08:40:47] step: 3000, train loss: 0.960, val loss: 0.957
[2025-08-29 08:43:15] step: 3500, train loss: 0.980, val loss: 0.970
[2025-08-29 08:45:41] step: 4000, train loss: 0.962, val loss: 0.964
[2025-08-29 08:47:55] step: 4500, train loss: 0.963, val loss: 0.960
[2025-08-29 08:50:07] step: 5000, train loss: 0.965, val loss: 0.956
[2025-08-29 08:52:18] step: 5500, train loss: 0.963, val loss: 0.952
[2025-08-29 08:54:29] step: 6000, train loss: 0.964, val loss: 0.973
[2025-08-29 08:56:44] step: 6500, train loss: 0.958, val loss: 0.953
[2025-08-29 08:58:58] step: 7000, train loss: 0.966, val loss: 0.961
[2025-08-29 09:01:08] step: 7500, train loss: 0.954, val loss: 0.957
[2025-08-29 09:03:19] step: 8000, train loss: 0.975, val loss: 0.934
[2025-08-29 09:05:33] step: 8500, train loss: 0.951, val loss: 0.936
[2025-08-29 09:07:44] step: 9000, train loss: 0.969, val loss: 0.957
[2025-08-29 09:09:59] step: 9500, train loss: 0.949, val loss: 0.967

[2025-08-29 09:26:48] step: 0, train loss: 0.951, val loss: 0.947
[2025-08-29 09:29:12] step: 500, train loss: 0.949, val loss: 0.947
[2025-08-29 09:31:42] step: 1000, train loss: 0.947, val loss: 0.955
[2025-08-29 09:34:16] step: 1500, train loss: 0.942, val loss: 0.947
[2025-08-29 09:36:45] step: 2000, train loss: 0.942, val loss: 0.957
[2025-08-29 09:39:14] step: 2500, train loss: 0.939, val loss: 0.950
[2025-08-29 09:41:42] step: 3000, train loss: 0.949, val loss: 0.955
[2025-08-29 09:44:14] step: 3500, train loss: 0.950, val loss: 0.944
[2025-08-29 09:46:45] step: 4000, train loss: 0.943, val loss: 0.958
[2025-08-29 09:49:14] step: 4500, train loss: 0.950, val loss: 0.955
[2025-08-29 09:51:42] step: 5000, train loss: 0.960, val loss: 0.958
[2025-08-29 09:54:05] step: 5500, train loss: 0.950, val loss: 0.958
[2025-08-29 09:56:28] step: 6000, train loss: 0.938, val loss: 0.942
[2025-08-29 09:58:54] step: 6500, train loss: 0.948, val loss: 0.955
[2025-08-29 10:01:20] step: 7000, train loss: 0.954, val loss: 0.942
[2025-08-29 10:03:45] step: 7500, train loss: 0.951, val loss: 0.936
[2025-08-29 10:06:09] step: 8000, train loss: 0.936, val loss: 0.959
[2025-08-29 10:08:32] step: 8500, train loss: 0.946, val loss: 0.945
[2025-08-29 10:10:54] step: 9000, train loss: 0.948, val loss: 0.942
[2025-08-29 10:13:16] step: 9500, train loss: 0.951, val loss: 0.934

[2025-08-29 10:17:06] step: 0, train loss: 0.952, val loss: 0.946
[2025-08-29 10:19:29] step: 500, train loss: 0.951, val loss: 0.953
[2025-08-29 10:21:42] step: 1000, train loss: 0.942, val loss: 0.935
[2025-08-29 10:23:58] step: 1500, train loss: 0.948, val loss: 0.955
[2025-08-29 10:26:16] step: 2000, train loss: 0.948, val loss: 0.945
[2025-08-29 10:28:33] step: 2500, train loss: 0.949, val loss: 0.943
[2025-08-29 10:30:53] step: 3000, train loss: 0.930, val loss: 0.945
[2025-08-29 10:33:12] step: 3500, train loss: 0.949, val loss: 0.939
[2025-08-29 10:35:40] step: 4000, train loss: 0.956, val loss: 0.940
[2025-08-29 10:37:58] step: 4500, train loss: 0.942, val loss: 0.937
[2025-08-29 10:40:20] step: 5000, train loss: 0.938, val loss: 0.938
[2025-08-29 10:42:43] step: 5500, train loss: 0.943, val loss: 0.945
[2025-08-29 10:45:01] step: 6000, train loss: 0.938, val loss: 0.939
[2025-08-29 10:47:20] step: 6500, train loss: 0.938, val loss: 0.939
[2025-08-29 10:49:43] step: 7000, train loss: 0.939, val loss: 0.938
[2025-08-29 10:52:04] step: 7500, train loss: 0.934, val loss: 0.944
[2025-08-29 10:54:24] step: 8000, train loss: 0.946, val loss: 0.940
[2025-08-29 10:56:47] step: 8500, train loss: 0.938, val loss: 0.933
[2025-08-29 10:59:06] step: 9000, train loss: 0.948, val loss: 0.941
[2025-08-29 11:01:27] step: 9500, train loss: 0.930, val loss: 0.945

[2025-08-29 11:14:20] step: 0, train loss: 2.113, val loss: 2.117

[2025-08-29 11:51:00] step: 0, train loss: 2.115, val loss: 2.108
[2025-08-29 11:53:37] step: 500, train loss: 1.655, val loss: 1.660
[2025-08-29 11:56:07] step: 1000, train loss: 1.492, val loss: 1.495
[2025-08-29 11:58:36] step: 1500, train loss: 0.934, val loss: 0.929
[2025-08-29 12:01:07] step: 2000, train loss: 0.923, val loss: 0.924
[2025-08-29 12:03:46] step: 2500, train loss: 0.902, val loss: 0.916
[2025-08-29 12:06:23] step: 3000, train loss: 0.909, val loss: 0.910
[2025-08-29 12:08:57] step: 3500, train loss: 0.912, val loss: 0.902
[2025-08-29 12:11:26] step: 4000, train loss: 0.909, val loss: 0.902
[2025-08-29 12:13:55] step: 4500, train loss: 0.891, val loss: 0.893
[2025-08-29 12:16:24] step: 5000, train loss: 0.902, val loss: 0.900
[2025-08-29 12:18:53] step: 5500, train loss: 0.904, val loss: 0.900

[2025-08-29 12:20:35] step: 0, train loss: 0.894, val loss: 0.902
[2025-08-29 12:23:04] step: 500, train loss: 0.891, val loss: 0.895
[2025-08-29 12:25:33] step: 1000, train loss: 0.913, val loss: 0.914
[2025-08-29 12:28:02] step: 1500, train loss: 0.909, val loss: 0.910
[2025-08-29 12:30:31] step: 2000, train loss: 0.893, val loss: 0.901
[2025-08-29 12:33:00] step: 2500, train loss: 0.896, val loss: 0.890
[2025-08-29 12:35:29] step: 3000, train loss: 0.895, val loss: 0.905
[2025-08-29 12:37:58] step: 3500, train loss: 0.893, val loss: 0.883
[2025-08-29 12:40:27] step: 4000, train loss: 0.900, val loss: 0.905
[2025-08-29 12:42:56] step: 4500, train loss: 0.893, val loss: 0.892
[2025-08-29 12:45:25] step: 5000, train loss: 0.895, val loss: 0.892
[2025-08-29 12:47:54] step: 5500, train loss: 0.897, val loss: 0.898
[2025-08-29 12:50:22] step: 6000, train loss: 0.893, val loss: 0.877
[2025-08-29 12:52:51] step: 6500, train loss: 0.883, val loss: 0.895
[2025-08-29 12:55:20] step: 7000, train loss: 0.888, val loss: 0.891
[2025-08-29 12:57:53] step: 7500, train loss: 0.896, val loss: 0.875
[2025-08-29 13:00:34] step: 8000, train loss: 0.886, val loss: 0.893
[2025-08-29 13:03:16] step: 8500, train loss: 0.891, val loss: 0.888
[2025-08-29 13:05:58] step: 9000, train loss: 0.894, val loss: 0.900
[2025-08-29 13:08:41] step: 9500, train loss: 0.895, val loss: 0.898

[2025-08-29 16:30:15] step: 0, train loss: 0.888, val loss: 0.899
[2025-08-29 16:35:35] step: 1000, train loss: 0.885, val loss: 0.893
[2025-08-29 16:40:59] step: 2000, train loss: 0.884, val loss: 0.897
[2025-08-29 16:46:28] step: 3000, train loss: 0.888, val loss: 0.892
[2025-08-29 16:51:38] step: 4000, train loss: 0.888, val loss: 0.893
[2025-08-29 16:57:03] step: 5000, train loss: 0.891, val loss: 0.900
[2025-08-29 17:02:37] step: 6000, train loss: 0.891, val loss: 0.894
[2025-08-29 17:08:14] step: 7000, train loss: 0.891, val loss: 0.888
[2025-08-29 17:13:44] step: 8000, train loss: 0.887, val loss: 0.898
[2025-08-29 17:19:09] step: 9000, train loss: 0.885, val loss: 0.896

[2025-08-29 17:32:09] step: 0, train loss: 0.887, val loss: 0.894
[2025-08-29 17:33:11] step: 200, train loss: 0.884, val loss: 0.873

[2025-08-29 17:37:49] step: 0, train loss: 0.885, val loss: 0.892
[2025-08-29 17:40:31] step: 500, train loss: 0.897, val loss: 0.878
[2025-08-29 17:43:14] step: 1000, train loss: 0.888, val loss: 0.883
[2025-08-29 17:45:56] step: 1500, train loss: 0.881, val loss: 0.863
[2025-08-29 17:48:39] step: 2000, train loss: 0.877, val loss: 0.895
[2025-08-29 17:51:21] step: 2500, train loss: 0.885, val loss: 0.880

[2025-08-29 18:00:07] step: 0, train loss: 0.880, val loss: 0.889
[2025-08-29 18:10:02] step: 2000, train loss: 0.880, val loss: 0.887
[2025-08-29 18:19:57] step: 4000, train loss: 0.878, val loss: 0.881
[2025-08-29 18:29:50] step: 6000, train loss: 0.877, val loss: 0.884
[2025-08-29 18:39:42] step: 8000, train loss: 0.880, val loss: 0.889
[2025-08-29 18:49:34] step: 10000, train loss: 0.878, val loss: 0.881
[2025-08-29 18:59:26] step: 12000, train loss: 0.876, val loss: 0.879
[2025-08-29 19:09:18] step: 14000, train loss: 0.880, val loss: 0.873
[2025-08-29 19:19:10] step: 16000, train loss: 0.866, val loss: 0.871
[2025-08-29 19:29:02] step: 18000, train loss: 0.876, val loss: 0.878
[2025-08-29 19:38:54] step: 20000, train loss: 0.881, val loss: 0.876
[2025-08-29 19:48:46] step: 22000, train loss: 0.878, val loss: 0.867
[2025-08-29 19:58:38] step: 24000, train loss: 0.870, val loss: 0.877
[2025-08-29 20:08:31] step: 26000, train loss: 0.876, val loss: 0.871
[2025-08-29 20:18:23] step: 28000, train loss: 0.870, val loss: 0.870
[2025-08-29 20:28:15] step: 30000, train loss: 0.876, val loss: 0.874
[2025-08-29 20:38:07] step: 32000, train loss: 0.874, val loss: 0.866
[2025-08-29 20:47:59] step: 34000, train loss: 0.870, val loss: 0.872
[2025-08-29 20:57:51] step: 36000, train loss: 0.874, val loss: 0.869
[2025-08-29 21:07:43] step: 38000, train loss: 0.867, val loss: 0.874

[2025-08-30 04:11:04] step: 0, train loss: 0.877, val loss: 0.875
[2025-08-30 04:20:59] step: 2000, train loss: 0.873, val loss: 0.867
[2025-08-30 04:30:53] step: 4000, train loss: 0.870, val loss: 0.872
[2025-08-30 04:40:46] step: 6000, train loss: 0.866, val loss: 0.873
[2025-08-30 04:50:38] step: 8000, train loss: 0.866, val loss: 0.863
[2025-08-30 05:00:31] step: 10000, train loss: 0.869, val loss: 0.865
[2025-08-30 05:10:24] step: 12000, train loss: 0.871, val loss: 0.873
[2025-08-30 05:20:16] step: 14000, train loss: 0.864, val loss: 0.870
[2025-08-30 05:30:08] step: 16000, train loss: 0.864, val loss: 0.866
[2025-08-30 05:40:00] step: 18000, train loss: 0.858, val loss: 0.870
[2025-08-30 05:49:53] step: 20000, train loss: 0.864, val loss: 0.860
[2025-08-30 05:59:45] step: 22000, train loss: 0.865, val loss: 0.866
[2025-08-30 06:09:37] step: 24000, train loss: 0.866, val loss: 0.865
[2025-08-30 06:19:39] step: 26000, train loss: 0.868, val loss: 0.860
[2025-08-30 06:30:26] step: 28000, train loss: 0.861, val loss: 0.864

[2026-01-09 21:00:14] step: 0, train loss: 3.840, val loss: 3.847
[2026-01-09 21:02:47] step: 500, train loss: 1.653, val loss: 1.650
[2026-01-09 21:05:19] step: 1000, train loss: 1.457, val loss: 1.462
[2026-01-09 21:07:54] step: 1500, train loss: 1.379, val loss: 1.363
[2026-01-09 21:10:38] step: 2000, train loss: 1.314, val loss: 1.318
[2026-01-09 21:13:22] step: 2500, train loss: 1.278, val loss: 1.283
[2026-01-09 21:16:06] step: 3000, train loss: 1.237, val loss: 1.243
[2026-01-09 21:18:49] step: 3500, train loss: 1.219, val loss: 1.226
[2026-01-09 21:21:27] step: 4000, train loss: 1.189, val loss: 1.200
[2026-01-09 21:24:06] step: 4500, train loss: 1.175, val loss: 1.167

[2026-01-09 21:46:14] step: 0, train loss: 1.167, val loss: 1.169
[2026-01-09 21:51:17] step: 1000, train loss: 1.130, val loss: 1.129
[2026-01-09 21:56:16] step: 2000, train loss: 1.109, val loss: 1.118
[2026-01-09 22:01:18] step: 3000, train loss: 1.098, val loss: 1.100
[2026-01-09 22:06:22] step: 4000, train loss: 1.080, val loss: 1.086
[2026-01-09 22:11:26] step: 5000, train loss: 1.058, val loss: 1.068
[2026-01-09 22:16:29] step: 6000, train loss: 1.048, val loss: 1.068
[2026-01-09 22:21:29] step: 7000, train loss: 1.037, val loss: 1.047

[2026-01-10 00:10:49] step: 0, train loss: 1.046, val loss: 1.042
[2026-01-10 00:16:12] step: 1000, train loss: 1.031, val loss: 1.036
[2026-01-10 00:21:36] step: 2000, train loss: 1.023, val loss: 1.024
[2026-01-10 00:26:50] step: 3000, train loss: 1.018, val loss: 1.018
[2026-01-10 00:32:11] step: 4000, train loss: 0.990, val loss: 1.000
[2026-01-10 00:37:34] step: 5000, train loss: 0.998, val loss: 1.000
[2026-01-10 00:42:57] step: 6000, train loss: 0.989, val loss: 0.995
[2026-01-10 00:48:22] step: 7000, train loss: 0.982, val loss: 0.994
[2026-01-10 00:53:49] step: 8000, train loss: 0.970, val loss: 0.978
[2026-01-10 00:59:28] step: 9000, train loss: 0.966, val loss: 0.975

[2026-01-10 01:12:12] step: 0, train loss: 0.964, val loss: 0.969
[2026-01-10 01:17:13] step: 1000, train loss: 0.957, val loss: 0.967
[2026-01-10 01:22:09] step: 2000, train loss: 0.949, val loss: 0.965
[2026-01-10 01:27:04] step: 3000, train loss: 0.956, val loss: 0.951
[2026-01-10 01:32:00] step: 4000, train loss: 0.947, val loss: 0.950
[2026-01-10 01:36:56] step: 5000, train loss: 0.939, val loss: 0.946
[2026-01-10 01:41:51] step: 6000, train loss: 0.929, val loss: 0.941
[2026-01-10 01:46:46] step: 7000, train loss: 0.934, val loss: 0.939
[2026-01-10 01:51:41] step: 8000, train loss: 0.930, val loss: 0.935
[2026-01-10 01:56:36] step: 9000, train loss: 0.924, val loss: 0.934
[2026-01-10 02:01:30] step: 10000, train loss: 0.912, val loss: 0.926
[2026-01-10 02:06:25] step: 11000, train loss: 0.918, val loss: 0.921
[2026-01-10 02:11:21] step: 12000, train loss: 0.907, val loss: 0.926
[2026-01-10 02:16:15] step: 13000, train loss: 0.915, val loss: 0.922
[2026-01-10 02:21:11] step: 14000, train loss: 0.906, val loss: 0.923
[2026-01-10 02:26:06] step: 15000, train loss: 0.902, val loss: 0.916
[2026-01-10 02:31:00] step: 16000, train loss: 0.902, val loss: 0.916
[2026-01-10 02:35:55] step: 17000, train loss: 0.900, val loss: 0.908
[2026-01-10 02:40:50] step: 18000, train loss: 0.894, val loss: 0.911
[2026-01-10 02:45:44] step: 19000, train loss: 0.898, val loss: 0.904
[2026-01-10 02:50:39] step: 20000, train loss: 0.888, val loss: 0.904
[2026-01-10 02:55:33] step: 21000, train loss: 0.890, val loss: 0.901
[2026-01-10 03:00:28] step: 22000, train loss: 0.889, val loss: 0.895
[2026-01-10 03:05:23] step: 23000, train loss: 0.878, val loss: 0.895
[2026-01-10 03:10:18] step: 24000, train loss: 0.876, val loss: 0.900
[2026-01-10 03:15:13] step: 25000, train loss: 0.881, val loss: 0.892
[2026-01-10 03:20:07] step: 26000, train loss: 0.872, val loss: 0.890
[2026-01-10 03:25:02] step: 27000, train loss: 0.873, val loss: 0.891
[2026-01-10 03:29:56] step: 28000, train loss: 0.866, val loss: 0.886
[2026-01-10 03:34:51] step: 29000, train loss: 0.863, val loss: 0.883

[2026-01-11 03:08:57] step: 0, train loss: 1.191, val loss: 1.185
[2026-01-11 03:11:37] step: 500, train loss: 1.085, val loss: 1.069
[2026-01-11 03:14:21] step: 1000, train loss: 1.053, val loss: 1.060
[2026-01-11 03:17:03] step: 1500, train loss: 1.053, val loss: 1.054

[2026-01-11 03:20:19] step: 0, train loss: 1.034, val loss: 1.040
[2026-01-11 03:23:01] step: 500, train loss: 1.034, val loss: 1.024
[2026-01-11 03:25:41] step: 1000, train loss: 1.014, val loss: 1.012
[2026-01-11 03:28:21] step: 1500, train loss: 1.025, val loss: 1.007

[2026-01-11 03:31:23] step: 0, train loss: 1.006, val loss: 1.019
[2026-01-11 03:34:06] step: 500, train loss: 0.998, val loss: 0.991
[2026-01-11 03:36:47] step: 1000, train loss: 0.997, val loss: 1.003
[2026-01-11 03:39:29] step: 1500, train loss: 0.989, val loss: 0.990

[2026-01-11 03:43:31] step: 0, train loss: 0.993, val loss: 0.990
[2026-01-11 03:48:54] step: 1000, train loss: 0.986, val loss: 0.988
[2026-01-11 03:54:17] step: 2000, train loss: 0.975, val loss: 0.982
[2026-01-11 03:59:38] step: 3000, train loss: 0.971, val loss: 0.978
[2026-01-11 04:05:02] step: 4000, train loss: 0.968, val loss: 0.971

[2026-01-11 04:10:53] step: 0, train loss: 0.970, val loss: 0.960
[2026-01-11 04:16:17] step: 1000, train loss: 0.963, val loss: 0.958
[2026-01-11 04:21:40] step: 2000, train loss: 0.954, val loss: 0.957
[2026-01-11 04:27:03] step: 3000, train loss: 0.948, val loss: 0.958
[2026-01-11 04:32:26] step: 4000, train loss: 0.947, val loss: 0.955
[2026-01-11 04:37:49] step: 5000, train loss: 0.943, val loss: 0.949

[2026-01-11 04:43:38] step: 0, train loss: 0.944, val loss: 0.944
[2026-01-11 04:48:50] step: 1000, train loss: 0.944, val loss: 0.939
[2026-01-11 04:53:55] step: 2000, train loss: 0.944, val loss: 0.937
[2026-01-11 04:59:20] step: 3000, train loss: 0.934, val loss: 0.926
[2026-01-11 05:04:43] step: 4000, train loss: 0.933, val loss: 0.929
[2026-01-11 05:10:02] step: 5000, train loss: 0.933, val loss: 0.923

[2026-01-11 05:13:41] step: 0, train loss: 0.939, val loss: 0.945
[2026-01-11 05:19:04] step: 1000, train loss: 0.938, val loss: 0.940
[2026-01-11 05:24:26] step: 2000, train loss: 0.937, val loss: 0.936
[2026-01-11 05:29:49] step: 3000, train loss: 0.935, val loss: 0.935
[2026-01-11 05:34:50] step: 4000, train loss: 0.929, val loss: 0.931
[2026-01-11 05:39:47] step: 5000, train loss: 0.926, val loss: 0.930
[2026-01-11 05:44:44] step: 6000, train loss: 0.922, val loss: 0.930
[2026-01-11 05:49:40] step: 7000, train loss: 0.918, val loss: 0.915
[2026-01-11 05:54:36] step: 8000, train loss: 0.922, val loss: 0.928
[2026-01-11 05:59:32] step: 9000, train loss: 0.927, val loss: 0.913
[2026-01-11 06:04:27] step: 10000, train loss: 0.914, val loss: 0.917
[2026-01-11 06:09:22] step: 11000, train loss: 0.922, val loss: 0.920
[2026-01-11 06:14:17] step: 12000, train loss: 0.912, val loss: 0.921
[2026-01-11 06:19:12] step: 13000, train loss: 0.919, val loss: 0.918
[2026-01-11 06:24:07] step: 14000, train loss: 0.909, val loss: 0.914
[2026-01-11 06:29:02] step: 15000, train loss: 0.902, val loss: 0.914
[2026-01-11 06:33:57] step: 16000, train loss: 0.898, val loss: 0.904
[2026-01-11 06:38:52] step: 17000, train loss: 0.906, val loss: 0.907
[2026-01-11 06:43:47] step: 18000, train loss: 0.908, val loss: 0.911
[2026-01-11 06:48:41] step: 19000, train loss: 0.905, val loss: 0.908
[2026-01-11 06:53:36] step: 20000, train loss: 0.902, val loss: 0.900
[2026-01-11 06:58:31] step: 21000, train loss: 0.909, val loss: 0.893
[2026-01-11 07:03:26] step: 22000, train loss: 0.904, val loss: 0.907
[2026-01-11 07:08:20] step: 23000, train loss: 0.899, val loss: 0.903
[2026-01-11 07:13:15] step: 24000, train loss: 0.892, val loss: 0.901
[2026-01-11 07:18:10] step: 25000, train loss: 0.896, val loss: 0.893
[2026-01-11 07:23:05] step: 26000, train loss: 0.892, val loss: 0.896
[2026-01-11 07:27:59] step: 27000, train loss: 0.883, val loss: 0.890
[2026-01-11 07:32:54] step: 28000, train loss: 0.892, val loss: 0.895
[2026-01-11 07:37:49] step: 29000, train loss: 0.888, val loss: 0.885

[2026-01-12 23:31:40] step: 0, train loss: 1.023, val loss: 1.026
[2026-01-12 23:37:00] step: 1000, train loss: 0.893, val loss: 0.901
[2026-01-12 23:42:15] step: 2000, train loss: 0.871, val loss: 0.870
[2026-01-12 23:47:32] step: 3000, train loss: 0.849, val loss: 0.854
[2026-01-12 23:52:50] step: 4000, train loss: 0.840, val loss: 0.840
[2026-01-12 23:58:05] step: 5000, train loss: 0.824, val loss: 0.828
[2026-01-13 00:03:20] step: 6000, train loss: 0.819, val loss: 0.821
[2026-01-13 00:08:37] step: 7000, train loss: 0.818, val loss: 0.812
[2026-01-13 00:13:57] step: 8000, train loss: 0.802, val loss: 0.809
[2026-01-13 00:19:12] step: 9000, train loss: 0.797, val loss: 0.805
[2026-01-13 00:24:38] step: 10000, train loss: 0.796, val loss: 0.801
[2026-01-13 00:29:37] step: 11000, train loss: 0.792, val loss: 0.795
[2026-01-13 00:35:11] step: 12000, train loss: 0.788, val loss: 0.786
[2026-01-13 00:40:29] step: 13000, train loss: 0.785, val loss: 0.782
[2026-01-13 00:45:45] step: 14000, train loss: 0.775, val loss: 0.777

[2026-01-13 15:46:41] step: 0, train loss: 0.776, val loss: 0.780
[2026-01-13 15:51:54] step: 1000, train loss: 0.777, val loss: 0.777
[2026-01-13 15:57:07] step: 2000, train loss: 0.769, val loss: 0.770
[2026-01-13 16:02:07] step: 3000, train loss: 0.766, val loss: 0.770
[2026-01-13 16:07:08] step: 4000, train loss: 0.763, val loss: 0.768

[2026-01-13 16:44:05] step: 0, train loss: 0.759, val loss: 0.761
[2026-01-13 16:48:58] step: 1000, train loss: 0.753, val loss: 0.765
[2026-01-13 16:53:54] step: 2000, train loss: 0.752, val loss: 0.759
[2026-01-13 16:58:45] step: 3000, train loss: 0.751, val loss: 0.761

[2026-01-13 22:58:39] step: 0, train loss: 1.480, val loss: 1.478
[2026-01-13 23:03:28] step: 1000, train loss: 0.501, val loss: 1.144
[2026-01-14 18:33:20] step: 0, train loss: 11.006, val loss: 11.007
[2026-01-14 18:36:06] step: 100, train loss: 7.223, val loss: 7.207
[2026-01-14 18:41:28] step: 200, train loss: 6.864, val loss: 6.882
[2026-01-14 18:48:32] step: 300, train loss: 6.607, val loss: 6.725
[2026-01-14 18:53:23] step: 400, train loss: 6.563, val loss: 6.547

[2026-01-14 19:14:55] step: 0, train loss: 6.413, val loss: 6.407
[2026-01-14 19:45:16] step: 1000, train loss: 5.960, val loss: 5.966

[2026-01-14 20:50:19] step: 0, train loss: 5.972, val loss: 5.885
[2026-01-14 20:50:43] step: 10, train loss: 5.973, val loss: 5.639

[2026-01-14 20:57:03] step: 0, train loss: 11.029, val loss: 11.007
[2026-01-14 20:57:25] step: 10, train loss: 9.311, val loss: 9.395

[2026-01-14 21:01:25] step: 0, train loss: 10.961, val loss: 10.964
[2026-01-14 21:31:19] step: 1000, train loss: 6.109, val loss: 6.131
[2026-01-14 22:00:57] step: 2000, train loss: 5.744, val loss: 5.746
[2026-01-14 22:30:34] step: 3000, train loss: 5.507, val loss: 5.456
[2026-01-14 23:00:10] step: 4000, train loss: 5.233, val loss: 5.256
[2026-01-14 23:29:47] step: 5000, train loss: 4.989, val loss: 5.032
[2026-01-14 23:59:24] step: 6000, train loss: 4.877, val loss: 4.913
[2026-01-15 00:29:00] step: 7000, train loss: 4.718, val loss: 4.697
[2026-01-15 00:58:36] step: 8000, train loss: 4.637, val loss: 4.619
[2026-01-15 01:28:13] step: 9000, train loss: 4.533, val loss: 4.515

[2026-01-15 06:53:19] step: 0, train loss: 11.010, val loss: 11.014
[2026-01-15 07:24:00] step: 1000, train loss: 6.098, val loss: 6.134
[2026-01-15 07:54:42] step: 2000, train loss: 5.743, val loss: 5.735

[2026-01-15 15:00:31] step: 0, train loss: 4.560, val loss: 4.778
[2026-01-15 15:00:52] step: 10, train loss: 4.416, val loss: 4.467

[2026-01-15 15:07:06] step: 0, train loss: 4.532, val loss: 4.509
[2026-01-15 15:49:31] step: 1000, train loss: 4.550, val loss: 4.540
[2026-01-15 16:23:56] step: 2000, train loss: 4.425, val loss: 4.440
[2026-01-15 16:56:56] step: 3000, train loss: 4.288, val loss: 4.317
[2026-01-15 17:29:56] step: 4000, train loss: 4.269, val loss: 4.303
[2026-01-15 18:02:54] step: 5000, train loss: 4.230, val loss: 4.246
[2026-01-15 18:35:54] step: 6000, train loss: 4.136, val loss: 4.153
[2026-01-15 19:08:53] step: 7000, train loss: 4.099, val loss: 4.098
[2026-01-15 19:41:53] step: 8000, train loss: 4.072, val loss: 4.056
[2026-01-15 20:14:55] step: 9000, train loss: 3.991, val loss: 4.014

[2026-01-15 21:30:04] step: 0, train loss: 4.003, val loss: 4.009
[2026-01-15 22:15:58] step: 1000, train loss: 4.068, val loss: 4.057

[2026-01-15 23:01:36] step: 0, train loss: 4.043, val loss: 4.179
[2026-01-15 23:05:00] step: 100, train loss: 4.111, val loss: 4.142
[2026-01-15 23:08:27] step: 200, train loss: 4.140, val loss: 4.146
[2026-01-15 23:11:53] step: 300, train loss: 4.088, val loss: 4.101
[2026-01-15 23:15:18] step: 400, train loss: 3.921, val loss: 4.195

[2026-01-15 23:22:23] step: 0, train loss: 4.107, val loss: 4.094
[2026-01-15 23:26:52] step: 100, train loss: 4.209, val loss: 4.175
[2026-01-15 23:31:30] step: 200, train loss: 4.239, val loss: 4.150
[2026-01-15 23:35:47] step: 300, train loss: 4.156, val loss: 4.205
[2026-01-15 23:40:14] step: 400, train loss: 4.188, val loss: 4.177

[2026-01-15 23:59:27] step: 0, train loss: 4.672, val loss: 4.637

[2026-01-16 00:03:48] step: 0, train loss: 4.625, val loss: 4.597
[2026-01-16 00:17:43] step: 0, train loss: 4.328, val loss: 4.239
[2026-01-16 00:18:00] step: 10, train loss: 4.449, val loss: 4.286

[2026-01-16 00:18:59] step: 0, train loss: 4.475, val loss: 4.534
[2026-01-16 00:19:19] step: 10, train loss: 4.142, val loss: 4.324

[2026-01-16 00:20:42] step: 0, train loss: 4.310, val loss: 4.263
[2026-01-16 00:21:00] step: 10, train loss: 4.504, val loss: 4.428

[2026-01-16 00:24:17] step: 0, train loss: 4.432, val loss: 4.307
[2026-01-16 00:24:36] step: 10, train loss: 4.400, val loss: 4.553
[2026-01-16 00:24:54] Training sequence completed

[2026-01-16 00:32:50] step: 0, train loss: 4.377, val loss: 4.379
[2026-01-16 01:12:08] step: 1000, train loss: 4.144, val loss: 4.168
[2026-01-16 01:48:44] step: 2000, train loss: 3.940, val loss: 4.012
[2026-01-16 02:25:19] step: 3000, train loss: 3.867, val loss: 3.916
[2026-01-16 03:01:55] step: 4000, train loss: 3.741, val loss: 3.850
[2026-01-16 03:38:27] step: 5000, train loss: 3.649, val loss: 3.749
[2026-01-16 04:15:00] step: 6000, train loss: 3.644, val loss: 3.717
[2026-01-16 04:51:35] step: 7000, train loss: 3.547, val loss: 3.652
[2026-01-16 05:28:09] step: 8000, train loss: 3.492, val loss: 3.640
[2026-01-16 06:04:44] step: 9000, train loss: 3.411, val loss: 3.605
[2026-01-16 06:38:16] Training sequence completed

[2026-01-16 06:58:17] step: 0, train loss: 3.387, val loss: 3.549
[2026-01-16 07:23:30] step: 1000, train loss: 3.417, val loss: 3.616
[2026-01-16 07:48:42] step: 2000, train loss: 3.375, val loss: 3.577
[2026-01-16 08:13:57] step: 3000, train loss: 3.339, val loss: 3.526
[2026-01-16 08:39:09] step: 4000, train loss: 3.286, val loss: 3.514
[2026-01-16 09:04:22] step: 5000, train loss: 3.256, val loss: 3.485
[2026-01-16 09:29:34] step: 6000, train loss: 3.202, val loss: 3.471
[2026-01-16 09:54:47] step: 7000, train loss: 3.201, val loss: 3.478
[2026-01-16 10:20:00] step: 8000, train loss: 3.149, val loss: 3.409
[2026-01-16 10:45:12] step: 9000, train loss: 3.146, val loss: 3.416
[2026-01-16 11:10:24] step: 10000, train loss: 3.104, val loss: 3.413
[2026-01-16 11:35:37] step: 11000, train loss: 3.095, val loss: 3.344
[2026-01-16 12:00:48] step: 12000, train loss: 3.052, val loss: 3.385
[2026-01-16 12:26:00] step: 13000, train loss: 3.034, val loss: 3.357
[2026-01-16 12:48:13] Training sequence completed
