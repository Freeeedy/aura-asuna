[2025-08-28 01:22:39] step: 0, train loss: 1.118, val loss: 1.126
[2025-08-28 01:26:37] step: 500, train loss: 1.127, val loss: 1.121

[2025-08-28 01:29:19] step: 0, train loss: 1.116, val loss: 1.118
[2025-08-28 01:33:18] step: 500, train loss: 1.115, val loss: 1.131
[2025-08-28 01:37:39] step: 1000, train loss: 1.117, val loss: 1.122
[2025-08-28 01:41:23] step: 1500, train loss: 1.121, val loss: 1.121
[2025-08-28 01:45:07] step: 2000, train loss: 1.103, val loss: 1.119
[2025-08-28 01:48:51] step: 2500, train loss: 1.125, val loss: 1.132
[2025-08-28 01:52:39] step: 3000, train loss: 1.116, val loss: 1.123
[2025-08-28 01:57:33] step: 3500, train loss: 1.110, val loss: 1.118
[2025-08-28 02:01:31] step: 4000, train loss: 1.114, val loss: 1.109
[2025-08-28 02:05:27] step: 4500, train loss: 1.113, val loss: 1.106
[2025-08-28 02:09:28] step: 5000, train loss: 1.101, val loss: 1.108
[2025-08-28 02:13:42] step: 5500, train loss: 1.107, val loss: 1.103
[2025-08-28 02:17:59] step: 6000, train loss: 1.101, val loss: 1.101
[2025-08-28 02:22:58] step: 6500, train loss: 1.106, val loss: 1.123
[2025-08-28 02:27:02] step: 7000, train loss: 1.110, val loss: 1.120
[2025-08-28 02:31:00] step: 7500, train loss: 1.094, val loss: 1.131
[2025-08-28 02:34:59] step: 8000, train loss: 1.106, val loss: 1.116
[2025-08-28 02:38:56] step: 8500, train loss: 1.109, val loss: 1.110
[2025-08-28 02:42:53] step: 9000, train loss: 1.128, val loss: 1.119
[2025-08-28 02:46:50] step: 9500, train loss: 1.107, val loss: 1.114
[2025-08-28 02:50:48] step: 10000, train loss: 1.099, val loss: 1.108
[2025-08-28 02:54:49] step: 10500, train loss: 1.105, val loss: 1.101
[2025-08-28 02:58:49] step: 11000, train loss: 1.115, val loss: 1.111
[2025-08-28 03:02:46] step: 11500, train loss: 1.101, val loss: 1.100
[2025-08-28 03:06:43] step: 12000, train loss: 1.114, val loss: 1.106
[2025-08-28 03:10:40] step: 12500, train loss: 1.101, val loss: 1.116
[2025-08-28 03:14:37] step: 13000, train loss: 1.105, val loss: 1.104
[2025-08-28 03:18:30] step: 13500, train loss: 1.106, val loss: 1.120
[2025-08-28 03:22:22] step: 14000, train loss: 1.109, val loss: 1.112
[2025-08-28 03:26:15] step: 14500, train loss: 1.114, val loss: 1.126

[2025-08-28 04:02:43] step: 0, train loss: 1.105, val loss: 1.111

[2025-08-28 04:24:36] step: 0, train loss: 1.109, val loss: 1.086

[2025-08-28 04:58:11] step: 0, train loss: 1.133, val loss: 1.117
[2025-08-28 05:06:14] step: 1000, train loss: 1.117, val loss: 1.116
[2025-08-28 05:13:55] step: 2000, train loss: 1.112, val loss: 1.107
[2025-08-28 05:21:23] step: 3000, train loss: 1.098, val loss: 1.114
[2025-08-28 05:28:51] step: 4000, train loss: 1.114, val loss: 1.121
[2025-08-28 05:36:20] step: 5000, train loss: 1.109, val loss: 1.109
[2025-08-28 05:43:49] step: 6000, train loss: 1.106, val loss: 1.120
[2025-08-28 05:51:18] step: 7000, train loss: 1.097, val loss: 1.097
[2025-08-28 05:58:46] step: 8000, train loss: 1.097, val loss: 1.109
[2025-08-28 06:06:13] step: 9000, train loss: 1.116, val loss: 1.124
[2025-08-28 06:13:39] step: 10000, train loss: 1.105, val loss: 1.101
[2025-08-28 06:21:05] step: 11000, train loss: 1.106, val loss: 1.098
[2025-08-28 06:28:31] step: 12000, train loss: 1.095, val loss: 1.108
[2025-08-28 06:35:57] step: 13000, train loss: 1.105, val loss: 1.114
[2025-08-28 06:43:23] step: 14000, train loss: 1.102, val loss: 1.091
[2025-08-28 06:50:49] step: 15000, train loss: 1.112, val loss: 1.107
[2025-08-28 06:58:15] step: 16000, train loss: 1.091, val loss: 1.096
[2025-08-28 07:05:41] step: 17000, train loss: 1.100, val loss: 1.106
[2025-08-28 07:13:08] step: 18000, train loss: 1.102, val loss: 1.111
[2025-08-28 07:20:35] step: 19000, train loss: 1.101, val loss: 1.095
[2025-08-28 07:28:01] step: 20000, train loss: 1.104, val loss: 1.095
[2025-08-28 07:35:27] step: 21000, train loss: 1.092, val loss: 1.097
[2025-08-28 07:42:53] step: 22000, train loss: 1.095, val loss: 1.105
[2025-08-28 07:50:19] step: 23000, train loss: 1.100, val loss: 1.093
[2025-08-28 07:57:45] step: 24000, train loss: 1.084, val loss: 1.103
[2025-08-28 08:05:11] step: 25000, train loss: 1.114, val loss: 1.097
[2025-08-28 08:12:38] step: 26000, train loss: 1.092, val loss: 1.098
[2025-08-28 08:20:04] step: 27000, train loss: 1.093, val loss: 1.096
[2025-08-28 08:27:30] step: 28000, train loss: 1.089, val loss: 1.088
[2025-08-28 08:34:56] step: 29000, train loss: 1.088, val loss: 1.097
[2025-08-28 08:42:22] step: 30000, train loss: 1.095, val loss: 1.092
[2025-08-28 08:49:49] step: 31000, train loss: 1.095, val loss: 1.098
[2025-08-28 08:57:15] step: 32000, train loss: 1.091, val loss: 1.101

[2025-08-28 16:21:25] step: 0, train loss: 1.085, val loss: 1.108
[2025-08-28 16:25:09] step: 500, train loss: 1.100, val loss: 1.094
[2025-08-28 16:29:01] step: 1000, train loss: 1.085, val loss: 1.083
[2025-08-28 16:33:02] step: 1500, train loss: 1.082, val loss: 1.073
[2025-08-28 16:37:03] step: 2000, train loss: 1.101, val loss: 1.097
[2025-08-28 16:41:04] step: 2500, train loss: 1.098, val loss: 1.091

[2025-08-28 16:48:43] step: 0, train loss: 1.085, val loss: 1.088
[2025-08-28 16:49:30] step: 100, train loss: 1.105, val loss: 1.083

[2025-08-28 16:50:26] step: 0, train loss: 1.097, val loss: 1.131
[2025-08-28 16:51:12] step: 100, train loss: 1.087, val loss: 1.087
[2025-08-28 16:51:59] step: 200, train loss: 1.117, val loss: 1.085

[2025-08-28 16:55:39] step: 0, train loss: 1.092, val loss: 1.097
[2025-08-28 16:59:36] step: 500, train loss: 1.093, val loss: 1.083
[2025-08-28 17:03:37] step: 1000, train loss: 1.087, val loss: 1.085
[2025-08-28 17:07:39] step: 1500, train loss: 1.102, val loss: 1.102

[2025-08-28 17:46:19] step: 0, train loss: 1.092, val loss: 1.093

[2025-08-28 18:30:11] step: 0, train loss: 1.086, val loss: 1.082
[2025-08-28 18:38:09] step: 1000, train loss: 1.088, val loss: 1.084
[2025-08-28 18:46:07] step: 2000, train loss: 1.079, val loss: 1.089
[2025-08-28 18:54:02] step: 3000, train loss: 1.096, val loss: 1.093
[2025-08-28 19:01:35] step: 4000, train loss: 1.085, val loss: 1.089
[2025-08-28 19:09:08] step: 5000, train loss: 1.088, val loss: 1.094
[2025-08-28 19:16:40] step: 6000, train loss: 1.085, val loss: 1.082
[2025-08-28 19:24:16] step: 7000, train loss: 1.089, val loss: 1.087
[2025-08-28 19:31:53] step: 8000, train loss: 1.093, val loss: 1.090
[2025-08-28 19:39:40] step: 9000, train loss: 1.087, val loss: 1.090

[2025-08-28 20:33:18] step: 0, train loss: 1.078, val loss: 1.079
[2025-08-28 20:41:20] step: 1000, train loss: 1.085, val loss: 1.090
[2025-08-28 20:49:24] step: 2000, train loss: 1.078, val loss: 1.097
[2025-08-28 20:57:11] step: 3000, train loss: 1.078, val loss: 1.088
[2025-08-28 21:04:48] step: 4000, train loss: 1.084, val loss: 1.080
[2025-08-28 21:12:33] step: 5000, train loss: 1.080, val loss: 1.096
[2025-08-28 21:20:27] step: 6000, train loss: 1.074, val loss: 1.078
[2025-08-28 21:28:23] step: 7000, train loss: 1.082, val loss: 1.091
[2025-08-28 21:36:17] step: 8000, train loss: 1.091, val loss: 1.083
[2025-08-28 21:44:13] step: 9000, train loss: 1.079, val loss: 1.075

[2025-08-29 06:49:50] step: 0, train loss: 2.278, val loss: 2.274
[2025-08-29 06:52:13] step: 500, train loss: 1.585, val loss: 1.598
[2025-08-29 06:54:25] step: 1000, train loss: 1.059, val loss: 1.060
[2025-08-29 06:56:38] step: 1500, train loss: 1.050, val loss: 1.033
[2025-08-29 06:59:00] step: 2000, train loss: 1.035, val loss: 1.020
[2025-08-29 07:01:23] step: 2500, train loss: 1.031, val loss: 1.031
[2025-08-29 07:03:48] step: 3000, train loss: 1.012, val loss: 1.013
[2025-08-29 07:06:14] step: 3500, train loss: 1.016, val loss: 1.010
[2025-08-29 07:08:37] step: 4000, train loss: 1.031, val loss: 1.014
[2025-08-29 07:11:02] step: 4500, train loss: 1.010, val loss: 1.006

[2025-08-29 07:15:02] step: 0, train loss: 0.998, val loss: 1.012
[2025-08-29 07:17:36] step: 500, train loss: 1.002, val loss: 1.008
[2025-08-29 07:20:02] step: 1000, train loss: 1.007, val loss: 0.999
[2025-08-29 07:22:31] step: 1500, train loss: 1.001, val loss: 0.995
[2025-08-29 07:24:44] step: 2000, train loss: 1.002, val loss: 1.006
[2025-08-29 07:26:55] step: 2500, train loss: 1.000, val loss: 1.001
[2025-08-29 07:29:05] step: 3000, train loss: 1.003, val loss: 0.987
[2025-08-29 07:31:16] step: 3500, train loss: 1.001, val loss: 0.990
[2025-08-29 07:33:27] step: 4000, train loss: 0.992, val loss: 0.991
[2025-08-29 07:35:38] step: 4500, train loss: 0.991, val loss: 0.980

[2025-08-29 07:38:19] step: 0, train loss: 0.985, val loss: 0.992
[2025-08-29 07:40:42] step: 500, train loss: 0.976, val loss: 0.980
[2025-08-29 07:43:04] step: 1000, train loss: 0.983, val loss: 0.992
[2025-08-29 07:45:28] step: 1500, train loss: 0.988, val loss: 0.996
[2025-08-29 07:47:52] step: 2000, train loss: 0.977, val loss: 0.975
[2025-08-29 07:50:17] step: 2500, train loss: 0.993, val loss: 0.982
[2025-08-29 07:52:38] step: 3000, train loss: 0.976, val loss: 0.980
[2025-08-29 07:54:52] step: 3500, train loss: 0.981, val loss: 0.974
[2025-08-29 07:57:13] step: 4000, train loss: 0.986, val loss: 0.969
[2025-08-29 07:59:37] step: 4500, train loss: 0.985, val loss: 0.984

[2025-08-29 08:02:55] step: 0, train loss: 0.983, val loss: 0.969
[2025-08-29 08:05:19] step: 500, train loss: 0.971, val loss: 0.966
[2025-08-29 08:07:43] step: 1000, train loss: 0.977, val loss: 0.967
[2025-08-29 08:10:08] step: 1500, train loss: 0.978, val loss: 0.966
[2025-08-29 08:12:29] step: 2000, train loss: 0.962, val loss: 0.969
[2025-08-29 08:14:44] step: 2500, train loss: 0.965, val loss: 0.967
[2025-08-29 08:17:00] step: 3000, train loss: 0.970, val loss: 0.970
[2025-08-29 08:19:16] step: 3500, train loss: 0.967, val loss: 0.954
[2025-08-29 08:21:34] step: 4000, train loss: 0.966, val loss: 0.977
[2025-08-29 08:23:51] step: 4500, train loss: 0.967, val loss: 0.974

[2025-08-29 08:26:31] step: 0, train loss: 0.970, val loss: 0.966
[2025-08-29 08:28:50] step: 500, train loss: 0.979, val loss: 0.962
[2025-08-29 08:31:11] step: 1000, train loss: 0.968, val loss: 0.971
[2025-08-29 08:33:32] step: 1500, train loss: 0.969, val loss: 0.977
[2025-08-29 08:35:55] step: 2000, train loss: 0.970, val loss: 0.972
[2025-08-29 08:38:20] step: 2500, train loss: 0.967, val loss: 0.963
[2025-08-29 08:40:47] step: 3000, train loss: 0.960, val loss: 0.957
[2025-08-29 08:43:15] step: 3500, train loss: 0.980, val loss: 0.970
[2025-08-29 08:45:41] step: 4000, train loss: 0.962, val loss: 0.964
[2025-08-29 08:47:55] step: 4500, train loss: 0.963, val loss: 0.960
[2025-08-29 08:50:07] step: 5000, train loss: 0.965, val loss: 0.956
[2025-08-29 08:52:18] step: 5500, train loss: 0.963, val loss: 0.952
[2025-08-29 08:54:29] step: 6000, train loss: 0.964, val loss: 0.973
[2025-08-29 08:56:44] step: 6500, train loss: 0.958, val loss: 0.953
[2025-08-29 08:58:58] step: 7000, train loss: 0.966, val loss: 0.961
[2025-08-29 09:01:08] step: 7500, train loss: 0.954, val loss: 0.957
[2025-08-29 09:03:19] step: 8000, train loss: 0.975, val loss: 0.934
[2025-08-29 09:05:33] step: 8500, train loss: 0.951, val loss: 0.936
[2025-08-29 09:07:44] step: 9000, train loss: 0.969, val loss: 0.957
[2025-08-29 09:09:59] step: 9500, train loss: 0.949, val loss: 0.967

[2025-08-29 09:26:48] step: 0, train loss: 0.951, val loss: 0.947
[2025-08-29 09:29:12] step: 500, train loss: 0.949, val loss: 0.947
[2025-08-29 09:31:42] step: 1000, train loss: 0.947, val loss: 0.955
[2025-08-29 09:34:16] step: 1500, train loss: 0.942, val loss: 0.947
[2025-08-29 09:36:45] step: 2000, train loss: 0.942, val loss: 0.957
[2025-08-29 09:39:14] step: 2500, train loss: 0.939, val loss: 0.950
[2025-08-29 09:41:42] step: 3000, train loss: 0.949, val loss: 0.955
[2025-08-29 09:44:14] step: 3500, train loss: 0.950, val loss: 0.944
[2025-08-29 09:46:45] step: 4000, train loss: 0.943, val loss: 0.958
[2025-08-29 09:49:14] step: 4500, train loss: 0.950, val loss: 0.955
[2025-08-29 09:51:42] step: 5000, train loss: 0.960, val loss: 0.958
[2025-08-29 09:54:05] step: 5500, train loss: 0.950, val loss: 0.958
[2025-08-29 09:56:28] step: 6000, train loss: 0.938, val loss: 0.942
[2025-08-29 09:58:54] step: 6500, train loss: 0.948, val loss: 0.955
[2025-08-29 10:01:20] step: 7000, train loss: 0.954, val loss: 0.942
[2025-08-29 10:03:45] step: 7500, train loss: 0.951, val loss: 0.936
[2025-08-29 10:06:09] step: 8000, train loss: 0.936, val loss: 0.959
[2025-08-29 10:08:32] step: 8500, train loss: 0.946, val loss: 0.945
[2025-08-29 10:10:54] step: 9000, train loss: 0.948, val loss: 0.942
[2025-08-29 10:13:16] step: 9500, train loss: 0.951, val loss: 0.934

[2025-08-29 10:17:06] step: 0, train loss: 0.952, val loss: 0.946
[2025-08-29 10:19:29] step: 500, train loss: 0.951, val loss: 0.953
[2025-08-29 10:21:42] step: 1000, train loss: 0.942, val loss: 0.935
[2025-08-29 10:23:58] step: 1500, train loss: 0.948, val loss: 0.955
[2025-08-29 10:26:16] step: 2000, train loss: 0.948, val loss: 0.945
[2025-08-29 10:28:33] step: 2500, train loss: 0.949, val loss: 0.943
[2025-08-29 10:30:53] step: 3000, train loss: 0.930, val loss: 0.945
[2025-08-29 10:33:12] step: 3500, train loss: 0.949, val loss: 0.939
[2025-08-29 10:35:40] step: 4000, train loss: 0.956, val loss: 0.940
[2025-08-29 10:37:58] step: 4500, train loss: 0.942, val loss: 0.937
[2025-08-29 10:40:20] step: 5000, train loss: 0.938, val loss: 0.938
[2025-08-29 10:42:43] step: 5500, train loss: 0.943, val loss: 0.945
[2025-08-29 10:45:01] step: 6000, train loss: 0.938, val loss: 0.939
[2025-08-29 10:47:20] step: 6500, train loss: 0.938, val loss: 0.939
[2025-08-29 10:49:43] step: 7000, train loss: 0.939, val loss: 0.938
[2025-08-29 10:52:04] step: 7500, train loss: 0.934, val loss: 0.944
[2025-08-29 10:54:24] step: 8000, train loss: 0.946, val loss: 0.940
[2025-08-29 10:56:47] step: 8500, train loss: 0.938, val loss: 0.933
[2025-08-29 10:59:06] step: 9000, train loss: 0.948, val loss: 0.941
[2025-08-29 11:01:27] step: 9500, train loss: 0.930, val loss: 0.945

[2025-08-29 11:14:20] step: 0, train loss: 2.113, val loss: 2.117

[2025-08-29 11:51:00] step: 0, train loss: 2.115, val loss: 2.108
[2025-08-29 11:53:37] step: 500, train loss: 1.655, val loss: 1.660
[2025-08-29 11:56:07] step: 1000, train loss: 1.492, val loss: 1.495
[2025-08-29 11:58:36] step: 1500, train loss: 0.934, val loss: 0.929
[2025-08-29 12:01:07] step: 2000, train loss: 0.923, val loss: 0.924
[2025-08-29 12:03:46] step: 2500, train loss: 0.902, val loss: 0.916
[2025-08-29 12:06:23] step: 3000, train loss: 0.909, val loss: 0.910
[2025-08-29 12:08:57] step: 3500, train loss: 0.912, val loss: 0.902
[2025-08-29 12:11:26] step: 4000, train loss: 0.909, val loss: 0.902
[2025-08-29 12:13:55] step: 4500, train loss: 0.891, val loss: 0.893
[2025-08-29 12:16:24] step: 5000, train loss: 0.902, val loss: 0.900
[2025-08-29 12:18:53] step: 5500, train loss: 0.904, val loss: 0.900

[2025-08-29 12:20:35] step: 0, train loss: 0.894, val loss: 0.902
[2025-08-29 12:23:04] step: 500, train loss: 0.891, val loss: 0.895
[2025-08-29 12:25:33] step: 1000, train loss: 0.913, val loss: 0.914
[2025-08-29 12:28:02] step: 1500, train loss: 0.909, val loss: 0.910
[2025-08-29 12:30:31] step: 2000, train loss: 0.893, val loss: 0.901
[2025-08-29 12:33:00] step: 2500, train loss: 0.896, val loss: 0.890
[2025-08-29 12:35:29] step: 3000, train loss: 0.895, val loss: 0.905
[2025-08-29 12:37:58] step: 3500, train loss: 0.893, val loss: 0.883
[2025-08-29 12:40:27] step: 4000, train loss: 0.900, val loss: 0.905
[2025-08-29 12:42:56] step: 4500, train loss: 0.893, val loss: 0.892
[2025-08-29 12:45:25] step: 5000, train loss: 0.895, val loss: 0.892
[2025-08-29 12:47:54] step: 5500, train loss: 0.897, val loss: 0.898
[2025-08-29 12:50:22] step: 6000, train loss: 0.893, val loss: 0.877
[2025-08-29 12:52:51] step: 6500, train loss: 0.883, val loss: 0.895
[2025-08-29 12:55:20] step: 7000, train loss: 0.888, val loss: 0.891
[2025-08-29 12:57:53] step: 7500, train loss: 0.896, val loss: 0.875
[2025-08-29 13:00:34] step: 8000, train loss: 0.886, val loss: 0.893
[2025-08-29 13:03:16] step: 8500, train loss: 0.891, val loss: 0.888
[2025-08-29 13:05:58] step: 9000, train loss: 0.894, val loss: 0.900
[2025-08-29 13:08:41] step: 9500, train loss: 0.895, val loss: 0.898

[2025-08-29 16:30:15] step: 0, train loss: 0.888, val loss: 0.899
[2025-08-29 16:35:35] step: 1000, train loss: 0.885, val loss: 0.893
[2025-08-29 16:40:59] step: 2000, train loss: 0.884, val loss: 0.897
[2025-08-29 16:46:28] step: 3000, train loss: 0.888, val loss: 0.892
[2025-08-29 16:51:38] step: 4000, train loss: 0.888, val loss: 0.893
[2025-08-29 16:57:03] step: 5000, train loss: 0.891, val loss: 0.900
[2025-08-29 17:02:37] step: 6000, train loss: 0.891, val loss: 0.894
[2025-08-29 17:08:14] step: 7000, train loss: 0.891, val loss: 0.888
[2025-08-29 17:13:44] step: 8000, train loss: 0.887, val loss: 0.898
[2025-08-29 17:19:09] step: 9000, train loss: 0.885, val loss: 0.896

[2025-08-29 17:32:09] step: 0, train loss: 0.887, val loss: 0.894
[2025-08-29 17:33:11] step: 200, train loss: 0.884, val loss: 0.873

[2025-08-29 17:37:49] step: 0, train loss: 0.885, val loss: 0.892
[2025-08-29 17:40:31] step: 500, train loss: 0.897, val loss: 0.878
[2025-08-29 17:43:14] step: 1000, train loss: 0.888, val loss: 0.883
[2025-08-29 17:45:56] step: 1500, train loss: 0.881, val loss: 0.863
[2025-08-29 17:48:39] step: 2000, train loss: 0.877, val loss: 0.895
[2025-08-29 17:51:21] step: 2500, train loss: 0.885, val loss: 0.880

[2025-08-29 18:00:07] step: 0, train loss: 0.880, val loss: 0.889
[2025-08-29 18:10:02] step: 2000, train loss: 0.880, val loss: 0.887
[2025-08-29 18:19:57] step: 4000, train loss: 0.878, val loss: 0.881
[2025-08-29 18:29:50] step: 6000, train loss: 0.877, val loss: 0.884
[2025-08-29 18:39:42] step: 8000, train loss: 0.880, val loss: 0.889
[2025-08-29 18:49:34] step: 10000, train loss: 0.878, val loss: 0.881
[2025-08-29 18:59:26] step: 12000, train loss: 0.876, val loss: 0.879
[2025-08-29 19:09:18] step: 14000, train loss: 0.880, val loss: 0.873
[2025-08-29 19:19:10] step: 16000, train loss: 0.866, val loss: 0.871
[2025-08-29 19:29:02] step: 18000, train loss: 0.876, val loss: 0.878
[2025-08-29 19:38:54] step: 20000, train loss: 0.881, val loss: 0.876
[2025-08-29 19:48:46] step: 22000, train loss: 0.878, val loss: 0.867
[2025-08-29 19:58:38] step: 24000, train loss: 0.870, val loss: 0.877
[2025-08-29 20:08:31] step: 26000, train loss: 0.876, val loss: 0.871
[2025-08-29 20:18:23] step: 28000, train loss: 0.870, val loss: 0.870
[2025-08-29 20:28:15] step: 30000, train loss: 0.876, val loss: 0.874
[2025-08-29 20:38:07] step: 32000, train loss: 0.874, val loss: 0.866
[2025-08-29 20:47:59] step: 34000, train loss: 0.870, val loss: 0.872
[2025-08-29 20:57:51] step: 36000, train loss: 0.874, val loss: 0.869
[2025-08-29 21:07:43] step: 38000, train loss: 0.867, val loss: 0.874

[2025-08-30 04:11:04] step: 0, train loss: 0.877, val loss: 0.875
[2025-08-30 04:20:59] step: 2000, train loss: 0.873, val loss: 0.867
[2025-08-30 04:30:53] step: 4000, train loss: 0.870, val loss: 0.872
[2025-08-30 04:40:46] step: 6000, train loss: 0.866, val loss: 0.873
[2025-08-30 04:50:38] step: 8000, train loss: 0.866, val loss: 0.863
[2025-08-30 05:00:31] step: 10000, train loss: 0.869, val loss: 0.865
[2025-08-30 05:10:24] step: 12000, train loss: 0.871, val loss: 0.873
[2025-08-30 05:20:16] step: 14000, train loss: 0.864, val loss: 0.870
[2025-08-30 05:30:08] step: 16000, train loss: 0.864, val loss: 0.866
[2025-08-30 05:40:00] step: 18000, train loss: 0.858, val loss: 0.870
[2025-08-30 05:49:53] step: 20000, train loss: 0.864, val loss: 0.860
[2025-08-30 05:59:45] step: 22000, train loss: 0.865, val loss: 0.866
[2025-08-30 06:09:37] step: 24000, train loss: 0.866, val loss: 0.865
[2025-08-30 06:19:39] step: 26000, train loss: 0.868, val loss: 0.860
[2025-08-30 06:30:26] step: 28000, train loss: 0.861, val loss: 0.864

[2026-01-09 21:00:14] step: 0, train loss: 3.840, val loss: 3.847
[2026-01-09 21:02:47] step: 500, train loss: 1.653, val loss: 1.650
[2026-01-09 21:05:19] step: 1000, train loss: 1.457, val loss: 1.462
[2026-01-09 21:07:54] step: 1500, train loss: 1.379, val loss: 1.363
[2026-01-09 21:10:38] step: 2000, train loss: 1.314, val loss: 1.318
[2026-01-09 21:13:22] step: 2500, train loss: 1.278, val loss: 1.283
[2026-01-09 21:16:06] step: 3000, train loss: 1.237, val loss: 1.243
[2026-01-09 21:18:49] step: 3500, train loss: 1.219, val loss: 1.226
[2026-01-09 21:21:27] step: 4000, train loss: 1.189, val loss: 1.200
[2026-01-09 21:24:06] step: 4500, train loss: 1.175, val loss: 1.167

[2026-01-09 21:46:14] step: 0, train loss: 1.167, val loss: 1.169
[2026-01-09 21:51:17] step: 1000, train loss: 1.130, val loss: 1.129
[2026-01-09 21:56:16] step: 2000, train loss: 1.109, val loss: 1.118
[2026-01-09 22:01:18] step: 3000, train loss: 1.098, val loss: 1.100
[2026-01-09 22:06:22] step: 4000, train loss: 1.080, val loss: 1.086
[2026-01-09 22:11:26] step: 5000, train loss: 1.058, val loss: 1.068
[2026-01-09 22:16:29] step: 6000, train loss: 1.048, val loss: 1.068
[2026-01-09 22:21:29] step: 7000, train loss: 1.037, val loss: 1.047
